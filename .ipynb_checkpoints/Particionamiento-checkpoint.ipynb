{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb35b72",
   "metadata": {},
   "source": [
    "# Muestreo Estratificado de Reseñas de Libros de Amazon\n",
    "Este cuaderno realiza una segmentación y muestreo estratificado de la base de datos de reseñas de libros. Se construyen particiones con base en puntuación y género, y se documenta el enfoque seguido para generar una muestra representativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd167830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar Spark\n",
    "import findspark, os, re\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config('spark.driver.memory', '16g') \\\n",
    "    .appName('AmazonBooks-Sampling') \\\n",
    "    .getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128a01b6-5257-4b7f-a691-d71cb00860f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mohamedbakhet/amazon-books-reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2fc880a-8f70-4a0d-a2c3-1337167ca863",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = spark.read.csv(path+\"/Books_rating.csv\",\n",
    "                    header=True,\n",
    "                    inferSchema=True,\n",
    "                    sep=\",\",\n",
    "                    quote='\"',        # <- Maneja correctamente los textos entre comillas\n",
    "                    escape='\"'        # <- (opcional) Escapa comillas internas si las hubiera\n",
    "                    )\n",
    "books = spark.read.csv(path+\"/books_data.csv\",\n",
    "                    header=True,\n",
    "                    inferSchema=True,\n",
    "                    sep=\",\",\n",
    "                    quote='\"',        # <- Maneja correctamente los textos entre comillas\n",
    "                    escape='\"'        # <- (opcional) Escapa comillas internas si las hubiera\n",
    "                    )\n",
    "full_data = reviews.join(books, on='Title', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98446106",
   "metadata": {},
   "source": [
    "## 1. Caracterización de la población\n",
    "Variables claves analizadas en la base de datos:\n",
    "\n",
    "| Variable | Dominio / Rango típico | Estadísticas |\n",
    "|----------|------------------------|--------------|\n",
    "| review/score | {1,2,3,4,5} | μ≈4.22 ; σ≈1.20 ; min 1 ; max 5 |\n",
    "| categories| 10964 categorias distintas | Top 10 cubre 90.23% de los datos |\n",
    "| price | 1 - 995 USD | μ≈21.76 ; σ≈26.20 ; min 1 ; max 995 |\n",
    "| description | 0-15000 caracteres | μ≈1.42k tokens ; σ≈0.97k tokens |\n",
    "| publishedDate | 101-2020+ (sin limpiar) | μ≈1983.8  ; σ≈32.5 |\n",
    "| ratingsCount | 1-4895+ |μ ≈ 21.25 ; σ ≈ 201.34 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13fe24f-5c62-441d-a8ea-59e86376a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cols = [\n",
    "    \"review/score\",\n",
    "    \"price\",\n",
    "    \"publishedDate\",\n",
    "    \"ratingsCount\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5dd303-f111-431e-b99b-a35441653848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Usando describe() — devuelve count, mean, stddev, min, max\n",
    "desc_df = full_data.select(cols).describe().toPandas()\n",
    "desc_transposed = desc_df.set_index('summary').T.drop('count', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fcf343e-ab0c-4a7b-bd3f-c3a8a732f74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary                      mean              stddev        min     max\n",
      "review/score    4.215289333333334  1.2030537472334044        1.0     5.0\n",
      "price            21.7626558749334  26.206540521370123        1.0   995.0\n",
      "publishedDate  1985.0539203308863   38.03038573196446  101-01-01    20??\n",
      "ratingsCount   272.09905936069714   788.8162145564309        1.0  4895.0\n"
     ]
    }
   ],
   "source": [
    "print(desc_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e875b827-c3a0-4f5f-80e5-1f2b796f268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"publishedDate\",\n",
    "    \"ratingsCount\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab35a8f9-0dde-4b2e-a862-dc52a28dc62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+----------------+-----------------+-----------------+------------------+\n",
      "|  count|min_chars|max_chars|      mean_chars|     stddev_chars|      mean_tokens|     stddev_tokens|\n",
      "+-------+---------+---------+----------------+-----------------+-----------------+------------------+\n",
      "|2359775|        1|    26092|722.179402697291|630.2005518026858|91.85404533333333|103.08612464092845|\n",
      "+-------+---------+---------+----------------+-----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_data = full_data \\\n",
    "    .withColumn('desc_len_chars', F.length(F.col('description'))) \\\n",
    "    .withColumn('desc_len_tokens', F.size(F.split(F.col('description'), r'\\s+')))\n",
    "\n",
    "stats_desc = full_data.agg(\n",
    "    F.count('description').alias('count'),\n",
    "    F.min('desc_len_chars').alias('min_chars'),\n",
    "    F.max('desc_len_chars').alias('max_chars'),\n",
    "    F.mean('desc_len_chars').alias('mean_chars'),\n",
    "    F.stddev('desc_len_chars').alias('stddev_chars'),\n",
    "    F.mean('desc_len_tokens').alias('mean_tokens'),\n",
    "    F.stddev('desc_len_tokens').alias('stddev_tokens')\n",
    ")\n",
    "stats_desc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bc9ad",
   "metadata": {},
   "source": [
    "## 2. Diseño de particiones\n",
    "Las particiones se crean a partir del producto cruzado entre:\n",
    "- **review_score_group**: Low (1–2), Mid (3), High (4–5)\n",
    "- **categories_group**: Fiction / Non-Fiction\n",
    "\n",
    "### Probabilidades empíricas por combinación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb756800-15eb-4bbd-ab30-06800d448b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------+---------------------+\n",
      "|R_group|C_group    |N      |Pr                   |\n",
      "+-------+-----------+-------+---------------------+\n",
      "|High   |Fiction    |38670  |0.01289              |\n",
      "|High   |Non‑Fiction|2354289|0.784763             |\n",
      "|Low    |Fiction    |3736   |0.0012453333333333333|\n",
      "|Low    |Non‑Fiction|349010 |0.11633666666666667  |\n",
      "|Mid    |Fiction    |3103   |0.0010343333333333333|\n",
      "|Mid    |Non‑Fiction|251192 |0.08373066666666666  |\n",
      "+-------+-----------+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, regexp_replace, split, explode\n",
    "\n",
    "# 1) Definir R_group\n",
    "full_data = full_data.withColumn(\n",
    "    \"R_group\",\n",
    "    when(col(\"review/score\") <= 2, \"Low\")\n",
    "    .when(col(\"review/score\") == 3, \"Mid\")\n",
    "    .otherwise(\"High\")\n",
    ")\n",
    "\n",
    "# 2) Definir C_group limpiando y usando la primera etiqueta\n",
    "#    (asume formato [\"Cat1\",\"Cat2\",…])\n",
    "full_data = full_data.withColumn(\n",
    "    \"first_cat\",\n",
    "    split(regexp_replace(col(\"categories\"), r\"^\\[|\\]$\", \"\"), r\",\\s*\")[0]\n",
    ")\n",
    "full_data = full_data.withColumn(\n",
    "    \"C_group\",\n",
    "    when(col(\"first_cat\").contains(\"fiction\"), \"Fiction\").otherwise(\"Non‑Fiction\")\n",
    ").drop(\"first_cat\")\n",
    "\n",
    "# 3) Ver probabilidades empíricas de cada combinación\n",
    "freqs = (\n",
    "    full_data\n",
    "    .groupBy(\"R_group\", \"C_group\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"N\")\n",
    "    .withColumn(\"Pr\", (col(\"N\") / full_data.count()).cast(\"double\"))\n",
    "    .orderBy(\"R_group\", \"C_group\")\n",
    ")\n",
    "freqs.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac39c0e5-e997-4a45-93de-7df61c7a6e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low×Fiction: 3,736 rows\n",
      "Low×Non‑Fiction: 349,010 rows\n",
      "Mid×Fiction: 3,103 rows\n",
      "Mid×Non‑Fiction: 251,192 rows\n",
      "High×Fiction: 38,670 rows\n",
      "High×Non‑Fiction: 2,354,289 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 1) Función auxiliar\n",
    "def get_partition(df, r_group: str, c_group: str):\n",
    "    return df.filter((col(\"R_group\") == r_group) & (col(\"C_group\") == c_group))\n",
    "\n",
    "# 2) Generar un dict con todos los estratos\n",
    "partitions = {}\n",
    "for rg in [\"Low\", \"Mid\", \"High\"]:\n",
    "    for cg in [\"Fiction\", \"Non‑Fiction\"]:\n",
    "        key = f\"{rg}×{cg}\"\n",
    "        partitions[key] = get_partition(full_data, rg, cg)\n",
    "\n",
    "# 3) Ver conteos de cada partición\n",
    "for key, df_part in partitions.items():\n",
    "    print(f\"{key}: {df_part.count():,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f822e67",
   "metadata": {},
   "source": [
    "## 3. Técnica de muestreo\n",
    "Se usará **muestreo aleatorio simple estratificado** (SRS) dentro de cada estrato (R_group x C_group) por estas razones:.\n",
    "\n",
    "**Control de heterogeneidad**: cada combinación de sentimiento (Low/Mid/High) y género (Fiction/Non‑Fiction) se trata como una subpoblación homogénea.\n",
    "\n",
    "**Minimización de sesgos**: al muestrear por estrato, evitamos que los grupos grandes dominen la muestra.\n",
    "\n",
    "**Asignación tipo Neyman**: definimos fracciones mayores en estratos pequeños para garantizar un tamaño de muestra mínimo, y menores en estratos muy grandes para eficiencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6bfe8",
   "metadata": {},
   "source": [
    "### Fórmula de tamaño de muestra de Cochran\n",
    "\n",
    "$$\n",
    "n_0 = \\frac{Z^2 \\cdot p \\cdot (1 - p)}{E^2}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- **n₀** = tamaño de muestra inicial para poblaciones grandes (antes de cualquier ajuste para poblaciones finitas)  \n",
    "- **Z** = valor z (por ejemplo, 1.96 para un 95 % de confianza)  \n",
    "- **p** = proporción poblacional estimada (usar 0.5 si se desconoce)  \n",
    "- **E** = margen de error  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70b284",
   "metadata": {},
   "source": [
    "#### Ajuste del tamaño de la muestra\n",
    "$$\n",
    "n_{adj} = \\frac{n_0}{1 + \\frac{n_0 - 1}{N}}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- **nₐdj** = tamaño de muestra ajustado  \n",
    "- **n₀** = tamaño de muestra inicial (calculado con la fórmula de Cochran u otras)  \n",
    "- **N** = tamaño total de la población  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "451fefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de muestra necesario: 16384.0\n",
      "Tamaño de muestra ajustado (población finita): 16296\n"
     ]
    }
   ],
   "source": [
    "#Definición del tamaño de muestra\n",
    "import math\n",
    "\n",
    "Z = 2.56 # 99% de confianza\n",
    "p = 0.5 # probabilidad de que el usuario le guste el libro\n",
    "E = 0.01 # margen de error\n",
    "\n",
    "n0 = (Z**2 * p * (1-p)) / (E**2)\n",
    "print(\"Tamaño de muestra necesario:\", n0)\n",
    "\n",
    "N = full_data.count() # población total\n",
    "\n",
    "n = n0 / (1 + ((n0 - 1) / N))\n",
    "n = math.ceil(n)\n",
    "print(f\"Tamaño de muestra ajustado (población finita): {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2c01c",
   "metadata": {},
   "source": [
    "### Fórmula para muestreo estratificado\n",
    "\n",
    "El muestreo estratificado se utiliza cuando una población puede dividirse en subgrupos distintos, o estratos, como grupos de edad, género o nivel educativo. El tamaño de muestra para cada estrato puede determinarse mediante el uso de la asignación proporcional:\n",
    "\n",
    "$$\n",
    "n_h = \\frac{N_h}{N} \\cdot n\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- **nₕ** = tamaño de muestra para el estrato h  \n",
    "- **Nₕ** = tamaño de la población en el estrato h  \n",
    "- **N** = tamaño total de la población  \n",
    "- **n** = tamaño total de la muestra  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34a03dc6-ae20-4c42-84da-a80dcbfe7f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----+\n",
      "|R_group|C_group    |count|\n",
      "+-------+-----------+-----+\n",
      "|High   |Fiction    |219  |\n",
      "|High   |Non‑Fiction|12849|\n",
      "|Low    |Fiction    |37   |\n",
      "|Low    |Non‑Fiction|1896 |\n",
      "|Mid    |Fiction    |54   |\n",
      "|Mid    |Non‑Fiction|1354 |\n",
      "+-------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws, col\n",
    "fraction = n / N\n",
    "\n",
    "\n",
    "# 1) Definición de frecuencias para obtener como mínimo 50 muestras por estrato\n",
    "fractions = {\n",
    "    \"Low×Fiction\":      50/3756,\n",
    "    \"Low×Non‑Fiction\":  fraction,\n",
    "    \"Mid×Fiction\":      50/3103,\n",
    "    \"Mid×Non‑Fiction\":  fraction,\n",
    "    \"High×Fiction\":     fraction,\n",
    "    \"High×Non‑Fiction\": fraction,\n",
    "}\n",
    "\n",
    "# 2) Creo la columna compuesta\n",
    "full2 = full_data.withColumn(\n",
    "    \"stratum\",\n",
    "    concat_ws(\"×\", col(\"R_group\"), col(\"C_group\"))\n",
    ")\n",
    "\n",
    "# 3) Muestreo estratificado usando esa columna\n",
    "sample_df = full2.stat.sampleBy(\"stratum\", fractions, seed=42)\n",
    "\n",
    "# 4) Veo el conteo por estrato para validar\n",
    "sample_df.groupBy(\"R_group\", \"C_group\") \\\n",
    "         .count() \\\n",
    "         .orderBy(\"R_group\", \"C_group\") \\\n",
    "         .show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f37d22a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----+---------+\n",
      "|R_group|    C_group|    N|MeanScore|\n",
      "+-------+-----------+-----+---------+\n",
      "|   High|    Fiction|  219|     4.84|\n",
      "|   High|Non‑Fiction|12849|     4.75|\n",
      "|    Low|    Fiction|   37|     1.32|\n",
      "|    Low|Non‑Fiction| 1896|     1.43|\n",
      "|    Mid|    Fiction|   54|      3.0|\n",
      "|    Mid|Non‑Fiction| 1354|      3.0|\n",
      "+-------+-----------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estadísticas exploratorias por grupo\n",
    "sample_df.groupBy('R_group', 'C_group') \\\n",
    "    .agg(F.count('*').alias('N'),\n",
    "         F.round(F.avg('review/score'),2).alias('MeanScore')) \\\n",
    "    .orderBy('R_group','C_group') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6da54a8-f109-41a5-b7a8-8203bfc81e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----+--------------------+\n",
      "|R_group|C_group    |N    |Pr                  |\n",
      "+-------+-----------+-----+--------------------+\n",
      "|High   |Fiction    |219  |0.013346334328722042|\n",
      "|High   |Non‑Fiction|12849|0.7830458894509111  |\n",
      "|Low    |Fiction    |37   |0.002254860137729295|\n",
      "|Low    |Non‑Fiction|1896 |0.11554634651715522 |\n",
      "|Mid    |Fiction    |54   |0.003290876957767079|\n",
      "|Mid    |Non‑Fiction|1354 |0.08251569260771528 |\n",
      "+-------+-----------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Verificación de probabilidades de cada combinación en la muestra\n",
    "#    (deberían ser similares a las de la población)\n",
    "#    (asume que la muestra es representativa)\n",
    "freqs_Sample = (\n",
    "    sample_df\n",
    "    .groupBy(\"R_group\", \"C_group\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"N\")\n",
    "    .withColumn(\"Pr\", (col(\"N\") / sample_df.count()).cast(\"double\"))\n",
    "    .orderBy(\"R_group\", \"C_group\")\n",
    ")\n",
    "freqs_Sample.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
